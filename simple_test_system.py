"""
Simple Test System - Test any PDF documents with any queries
"""

import os
import pandas as pd
from simple_pdf_processor import SimplePDFProcessor
from vector_store_manager import VectorStoreManager
from simple_rag_agent import SimpleRAGAgent
from rag_evaluator import RAGEvaluator


def get_sample_test_queries():
    """Sample queries you can modify based on your documents"""

    return [
        # General content queries
        "What is this document about?",
        "What are the main topics covered?",
        "What are the key points mentioned?",

        # Specific information queries
        "What details are provided about the main subject?",
        "What examples or cases are discussed?",
        "What recommendations or suggestions are made?",

        # Analysis queries
        "What problems or challenges are identified?",
        "What solutions or approaches are described?",
        "What conclusions are reached?",

        # Custom queries (modify these based on your documents)
        "What specific information is most important?",
        "What facts or data are presented?"
    ]


def simple_rag_test():
    """Simple RAG test with any documents and queries"""

    print("ðŸš€ SIMPLE RAG TEST")
    print("=" * 30)

    # Step 1: Initialize simple components
    print("\n1ï¸âƒ£ Initializing RAG system...")

    try:
        processor = SimplePDFProcessor()
        vector_manager = VectorStoreManager()
        rag_agent = SimpleRAGAgent(vector_manager)
        evaluator = RAGEvaluator()

        print("âœ… Simple RAG system initialized")

    except Exception as e:
        print(f"âŒ System initialization failed: {e}")
        return

    # Step 2: Process PDF documents
    print("\n2ï¸âƒ£ Processing PDF documents...")

    stats = vector_manager.get_collection_stats()

    if stats['total_chunks'] == 0:
        pdf_directory = "sample_pdfs"

        if not os.path.exists(pdf_directory):
            print(f"âŒ Directory '{pdf_directory}' not found")
            print("ðŸ’¡ Create the directory and add any PDF files")
            return

        try:
            documents = processor.process_pdfs(pdf_directory)

            if documents:
                vector_manager.add_documents(documents)
                print(f"âœ… Processed {len(documents)} documents")

                # Show what was processed
                print("\nðŸ“„ Document Summary:")
                for doc in documents:
                    print(f"   â€¢ {doc['document_name']}: {doc['word_count']:,} words")

            else:
                print("âŒ No documents were processed")
                return

        except Exception as e:
            print(f"âŒ Document processing failed: {e}")
            return
    else:
        print(f"âœ… Using existing {stats['total_chunks']} chunks")

    # Step 3: Test with sample queries
    print("\n3ï¸âƒ£ Testing with sample queries...")

    test_queries = get_sample_test_queries()

    # You can modify this to test specific queries
    selected_queries = test_queries[:5]  # Test first 5 queries

    print(f"ðŸ§ª Running {len(selected_queries)} test queries...")

    results = []

    for i, query in enumerate(selected_queries, 1):
        print(f"\n--- Query {i}/{len(selected_queries)} ---")
        print(f"â“ {query}")

        try:
            # Process query
            response = rag_agent.query(query, k=3)

            # Evaluate response
            metrics = evaluator.evaluate_response(response)

            # Store results
            result = {
                'query': query,
                'response': response.response,
                'sources': ', '.join(response.sources),
                'num_chunks': len(response.context_chunks),
                'response_length': len(response.response),
                **metrics
            }
            results.append(result)

            # Show results
            print(f"ðŸ“ Response: {response.response[:150]}...")
            print(f"ðŸ“š Sources: {', '.join(response.sources)}")
            print(f"ðŸ† RAG Score: {metrics['rag_score']:.3f}")

            # Simple quality indicator
            if metrics['rag_score'] >= 0.7:
                quality = "ðŸŸ¢ GOOD"
            elif metrics['rag_score'] >= 0.5:
                quality = "ðŸŸ¡ OK"
            else:
                quality = "ðŸ”´ NEEDS IMPROVEMENT"

            print(f"âœ… Quality: {quality}")

        except Exception as e:
            print(f"âŒ Query failed: {e}")
            continue

    # Step 4: Summary and results
    print("\n4ï¸âƒ£ Test Results Summary")
    print("=" * 30)

    if results:
        df = pd.DataFrame(results)

        # Save results
        df.to_csv("simple_rag_results.csv", index=False)
        print("ðŸ’¾ Results saved to: simple_rag_results.csv")

        # Summary statistics
        print(f"\nðŸ“Š Performance Summary:")
        print(f"   â€¢ Queries tested: {len(results)}")
        print(f"   â€¢ Average RAG Score: {df['rag_score'].mean():.3f}")
        print(f"   â€¢ Average Response Length: {df['response_length'].mean():.0f} chars")
        print(f"   â€¢ Documents used: {len(set(df['sources'].sum().split(', ')))}")

        # Best performing query
        best_idx = df['rag_score'].idxmax()
        print(f"\nðŸ† Best Query (Score: {df.loc[best_idx, 'rag_score']:.3f}):")
        print(f"   '{df.loc[best_idx, 'query']}'")

        # Quality distribution
        good = len(df[df['rag_score'] >= 0.7])
        ok = len(df[(df['rag_score'] >= 0.5) & (df['rag_score'] < 0.7)])
        poor = len(df[df['rag_score'] < 0.5])

        print(f"\nðŸ“ˆ Quality Distribution:")
        print(f"   â€¢ Good (â‰¥0.7): {good} queries")
        print(f"   â€¢ OK (0.5-0.7): {ok} queries")
        print(f"   â€¢ Poor (<0.5): {poor} queries")

    else:
        print("âŒ No results to analyze")

    print(f"\nâœ… Simple RAG test complete!")


def custom_query_test():
    """Test with your own custom queries"""

    print("\nðŸŽ¯ CUSTOM QUERY TEST")
    print("=" * 25)

    # Initialize system
    vector_manager = VectorStoreManager()
    rag_agent = SimpleRAGAgent(vector_manager)

    # Add your custom queries here
    custom_queries = [
        "YOUR CUSTOM QUERY 1",
        "YOUR CUSTOM QUERY 2",
        "YOUR CUSTOM QUERY 3"
    ]

    print("ðŸ’¡ Modify the custom_queries list in the code to test your specific questions")

    for i, query in enumerate(custom_queries, 1):
        print(f"\nðŸ” Query {i}: {query}")

        try:
            response = rag_agent.query(query, k=3)
            print(f"ðŸ“ Response: {response.response[:200]}...")
            print(f"ðŸ“š Sources: {', '.join(response.sources)}")

        except Exception as e:
            print(f"âŒ Error: {e}")


def interactive_query_test():
    """Interactive testing - type your own queries"""

    print("\nðŸ’¬ INTERACTIVE QUERY TEST")
    print("=" * 30)

    # Initialize system
    vector_manager = VectorStoreManager()
    rag_agent = SimpleRAGAgent(vector_manager)
    evaluator = RAGEvaluator()

    print("Type your queries (press Enter twice to finish):")

    while True:
        query = input("\nâ“ Your query: ").strip()

        if not query:
            break

        try:
            response = rag_agent.query(query, k=3)
            metrics = evaluator.evaluate_response(response)

            print(f"\nðŸ“ Response: {response.response}")
            print(f"ðŸ“š Sources: {', '.join(response.sources)}")
            print(f"ðŸ† Score: {metrics['rag_score']:.3f}")

        except Exception as e:
            print(f"âŒ Error: {e}")

    print("âœ… Interactive testing finished!")


if __name__ == "__main__":
    # Choose which test to run:
    simple_rag_test()  # Automated test with sample queries
    # custom_query_test()    # Test with your custom queries
    # interactive_query_test() # Type queries interactively